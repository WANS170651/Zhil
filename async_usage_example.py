#!/usr/bin/env python3
"""
å¼‚æ­¥ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨é‡æ„åçš„å¼‚æ­¥API
"""

import asyncio
import time
import sys
import os

# æ·»åŠ æºç è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.main_pipeline import process_url_async, process_urls_concurrent


async def example_single_url():
    """å•URLå¼‚æ­¥å¤„ç†ç¤ºä¾‹"""
    print("ğŸ”¥ å•URLå¼‚æ­¥å¤„ç†ç¤ºä¾‹")
    print("=" * 40)
    
    url = "https://httpbin.org/json"
    print(f"å¤„ç†URL: {url}")
    
    start_time = time.time()
    
    try:
        result = await process_url_async(url)
        processing_time = time.time() - start_time
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
        print(f"æˆåŠŸçŠ¶æ€: {result.get('success', False)}")
        
        if result.get('success'):
            print("ğŸ“Š å¤„ç†è¯¦æƒ…:")
            stage_times = result.get('stage_times', {})
            for stage, time_cost in stage_times.items():
                print(f"  {stage}: {time_cost:.2f}s")
        
        return result
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return None


async def example_concurrent_batch():
    """å¹¶å‘æ‰¹é‡å¤„ç†ç¤ºä¾‹"""
    print("\nğŸš€ å¹¶å‘æ‰¹é‡å¤„ç†ç¤ºä¾‹")
    print("=" * 40)
    
    urls = [
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/2", 
        "https://httpbin.org/delay/1",
        "https://httpbin.org/json",
    ]
    
    print(f"å¤„ç†URLæ•°é‡: {len(urls)}")
    
    start_time = time.time()
    
    try:
        report = await process_urls_concurrent(urls)
        processing_time = time.time() - start_time
        
        print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
        
        summary = report.get('summary', {})
        print(f"ğŸ“Š å¤„ç†æ‘˜è¦:")
        print(f"  æ€»æ•°: {summary.get('total_count', 0)}")
        print(f"  æˆåŠŸ: {summary.get('success_count', 0)}")
        print(f"  å¤±è´¥: {summary.get('failed_count', 0)}")
        print(f"  æˆåŠŸç‡: {summary.get('success_rate', 0):.1f}%")
        print(f"  é¢„è®¡åŠ é€Ÿæ¯”: {summary.get('estimated_speedup', 1):.1f}x")
        
        # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
        timing = report.get('timing', {})
        print(f"â±ï¸ æ—¶é—´ç»Ÿè®¡:")
        print(f"  æ€»å¤„ç†æ—¶é—´: {timing.get('total_time', 0):.2f}s")
        print(f"  å¹³å‡å¤„ç†æ—¶é—´: {timing.get('average_time', 0):.2f}s")
        print(f"  å®é™…å¢™é’Ÿæ—¶é—´: {timing.get('wall_clock_time', 0):.2f}s")
        
        return report
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        return None


async def performance_comparison():
    """æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹"""
    print("\nâš¡ æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹")
    print("=" * 40)
    
    urls = [
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/1",
    ]
    
    print(f"æµ‹è¯•URLæ•°é‡: {len(urls)}")
    
    # æ¨¡æ‹Ÿé¡ºåºå¤„ç†æ—¶é—´ï¼ˆå®é™…ä¸æ‰§è¡Œï¼Œåªæ˜¯ä¼°ç®—ï¼‰
    estimated_sequential_time = len(urls) * 2  # å‡è®¾æ¯ä¸ªURLé¡ºåºå¤„ç†éœ€è¦2ç§’
    print(f"é¢„è®¡é¡ºåºå¤„ç†æ—¶é—´: {estimated_sequential_time}s")
    
    # å¼‚æ­¥å¹¶å‘å¤„ç†
    print("ğŸš€ å¼€å§‹å¼‚æ­¥å¹¶å‘å¤„ç†...")
    start_time = time.time()
    
    try:
        report = await process_urls_concurrent(urls)
        actual_time = time.time() - start_time
        
        success_count = report.get('summary', {}).get('success_count', 0)
        speedup = estimated_sequential_time / actual_time if actual_time > 0 else 1
        
        print(f"âœ… å¹¶å‘å¤„ç†å®Œæˆ:")
        print(f"  å®é™…è€—æ—¶: {actual_time:.2f}s")
        print(f"  æˆåŠŸå¤„ç†: {success_count}/{len(urls)}")
        print(f"  ğŸš€ åŠ é€Ÿæ¯”: {speedup:.1f}x")
        print(f"  æ—¶é—´èŠ‚çœ: {((estimated_sequential_time - actual_time) / estimated_sequential_time * 100):.1f}%")
        
        return speedup
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½å¯¹æ¯”å¤±è´¥: {e}")
        return None


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¯ å¼‚æ­¥APIä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # ç¤ºä¾‹1: å•URLå¤„ç†
    await example_single_url()
    
    # ç¤ºä¾‹2: å¹¶å‘æ‰¹é‡å¤„ç†
    await example_concurrent_batch()
    
    # ç¤ºä¾‹3: æ€§èƒ½å¯¹æ¯”
    speedup = await performance_comparison()
    
    # æ€»ç»“
    print("\nğŸ‰ å¼‚æ­¥APIç¤ºä¾‹å®Œæˆï¼")
    print("=" * 60)
    
    print("ğŸ“ˆ é‡æ„æ”¶ç›Šæ€»ç»“:")
    print("âœ… çœŸæ­£çš„éé˜»å¡å¼‚æ­¥å¤„ç†")
    print("âœ… å¹¶å‘æ‰¹é‡å¤„ç†èƒ½åŠ›")
    print("âœ… æ™ºèƒ½å¹¶å‘æ§åˆ¶")
    print("âœ… æ˜¾è‘—çš„æ€§èƒ½æå‡")
    
    if speedup and speedup > 1:
        print(f"âœ… å®æµ‹åŠ é€Ÿæ¯”: {speedup:.1f}x")
    
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("- å•URLå¤„ç†: ä½¿ç”¨ process_url_async()")
    print("- æ‰¹é‡å¤„ç†: ä½¿ç”¨ process_urls_concurrent()")
    print("- å¤§æ‰¹é‡å¤„ç†: å»ºè®®åˆ†æ‰¹æ¬¡å¤„ç†ï¼Œé¿å…è¿‡åº¦å¹¶å‘")
    print("- APIç«¯ç‚¹: /ingest/url å’Œ /ingest/batch å·²é‡æ„ä¸ºå¼‚æ­¥")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç¤ºä¾‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
