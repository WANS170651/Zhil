"""
LLM Schema Builderæ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨LLM Schema Builderä¸ºä¸åŒåœºæ™¯ç”ŸæˆSchema
"""

import sys
import os
import json
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.notion_schema import get_database_schema
from src.llm_schema_builder import build_function_call_schema, build_system_prompt


def demo_openai_function_call():
    """æ¼”ç¤ºOpenAIå‡½æ•°è°ƒç”¨é›†æˆ"""
    print("ğŸš€ OpenAIå‡½æ•°è°ƒç”¨é›†æˆæ¼”ç¤º")
    print("="*50)
    
    # è·å–Schema
    notion_schema = get_database_schema()
    
    # ç”Ÿæˆå‡½æ•°è°ƒç”¨Schema
    function_schema = build_function_call_schema(notion_schema)
    system_prompt = build_system_prompt(notion_schema)
    
    print("ğŸ“‹ å‡½æ•°è°ƒç”¨é…ç½®:")
    print(f"å‡½æ•°å: {function_schema['name']}")
    print(f"å‚æ•°æ•°é‡: {len(function_schema['parameters']['properties'])}")
    print(f"å¿…å¡«å‚æ•°: {function_schema['parameters']['required']}")
    
    print("\nğŸ’¬ æ¨¡æ‹ŸLLMè°ƒç”¨ä»£ç :")
    print("""
from openai import OpenAI

client = OpenAI(
    api_key="your-api-key",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

response = client.chat.completions.create(
    model="qwen-flash",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": "ç½‘é¡µå†…å®¹: " + scraped_content}
    ],
    functions=[function_schema],
    function_call={"name": "extract_job_info"}
)

# è·å–å‡½æ•°è°ƒç”¨ç»“æœ
function_call = response.choices[0].message.function_call
extracted_data = json.loads(function_call.arguments)
""")
    
    print("\nâœ¨ è¿™å°±æ˜¯å®Œæ•´çš„LLMé›†æˆæ–¹æ¡ˆï¼")


def demo_schema_validation():
    """æ¼”ç¤ºSchemaéªŒè¯èƒ½åŠ›"""
    print("\nğŸ” SchemaéªŒè¯èƒ½åŠ›æ¼”ç¤º")
    print("="*50)
    
    notion_schema = get_database_schema()
    function_schema = build_function_call_schema(notion_schema)
    
    # æ¨¡æ‹ŸLLMè¾“å‡º
    mock_llm_output = {
        "Date": "2025-08-19",
        "Company": "å­—èŠ‚è·³åŠ¨",
        "Position": "é«˜çº§å‰ç«¯å·¥ç¨‹å¸ˆ",
        "Industry": "äº’è”ç½‘/ç§‘æŠ€",  # æ­£ç¡®çš„æšä¸¾å€¼
        "Status": "Applied",       # æ­£ç¡®çš„æšä¸¾å€¼
        "URL": "https://job.bytedance.com/example",
        "Location": "åŒ—äº¬Â·æœé˜³åŒº",
        "Requirements": "3å¹´ä»¥ä¸Šå‰ç«¯å¼€å‘ç»éªŒï¼Œç²¾é€šReact/Vue",
        "Notes": "å…¬å¸å‰æ™¯ä¸é”™ï¼Œå›¢é˜Ÿæ°›å›´å¥½"
    }
    
    print("âœ… æœ‰æ•ˆçš„LLMè¾“å‡ºç¤ºä¾‹:")
    for key, value in mock_llm_output.items():
        field_def = function_schema['parameters']['properties'].get(key, {})
        if 'enum' in field_def:
            status = "âœ“" if value in field_def['enum'] else "âœ—"
            print(f"  {status} {key}: {value} (æšä¸¾å­—æ®µ)")
        else:
            print(f"  âœ“ {key}: {value}")
    
    print("\nâŒ æ— æ•ˆè¾“å‡ºç¤ºä¾‹:")
    invalid_output = mock_llm_output.copy()
    invalid_output["Industry"] = "è‡ªåˆ›è¡Œä¸š"  # ä¸åœ¨æšä¸¾ä¸­
    invalid_output["Status"] = "è‡ªå®šä¹‰çŠ¶æ€"   # ä¸åœ¨æšä¸¾ä¸­
    
    for key, value in invalid_output.items():
        field_def = function_schema['parameters']['properties'].get(key, {})
        if 'enum' in field_def:
            status = "âœ“" if value in field_def['enum'] else "âœ—"
            print(f"  {status} {key}: {value}")
            if status == "âœ—":
                print(f"      å¯é€‰: {field_def['enum']}")


if __name__ == "__main__":
    print("ğŸ¯ LLM Schema BuilderåŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    demo_openai_function_call()
    demo_schema_validation()
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼LLM Schema Builderå·²ready for productionï¼")
